{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c42af",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "status_code: 400, body: {'id': 'e87387ae-1d15-4515-8885-c9268ab8d03b', 'message': 'too many tokens: max tokens must be less than or equal to 4096, the maximum output for this model - received 5000.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcohere\u001b[39;00m\n\u001b[32m      3\u001b[39m co = cohere.Client(\u001b[33m\"\u001b[39m\u001b[33mW0ZMiF8D4eU3eMGgZevXJMPwnJMzJVtd7JYwvo0V\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# No ClientV2 needed for most use cases\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m response = \u001b[43mco\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcommand-r\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or \"command-a-03-2025\" if you have access\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDo you know haribabu kuthmpeta\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.65\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# You can use just `message` for one-shot chat\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBot:\u001b[39m\u001b[33m\"\u001b[39m, response.text) \n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\cohere\\client.py:103\u001b[39m, in \u001b[36mexperimental_kwarg_decorator.<locals>._wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_kwarg(deprecated_kwarg, kwargs):\n\u001b[32m     99\u001b[39m     logger.warning(\n\u001b[32m    100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeprecated_kwarg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` parameter is an experimental feature and may change in future releases.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    101\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo suppress this warning, set `log_warning_experimental_features=False` when initializing the client.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    102\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\cohere\\client.py:35\u001b[39m, in \u001b[36mvalidate_args.<locals>._wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapped\u001b[39m(*args: typing.Any, **kwargs: typing.Any) -> typing.Any:\n\u001b[32m     34\u001b[39m     check_fn(*args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\cohere\\base_client.py:998\u001b[39m, in \u001b[36mBaseCohere.chat\u001b[39m\u001b[34m(self, message, accepts, model, preamble, chat_history, conversation_id, prompt_truncation, connectors, search_queries_only, documents, citation_quality, temperature, max_tokens, max_input_tokens, k, p, seed, stop_sequences, frequency_penalty, presence_penalty, raw_prompting, return_prompt, tools, tool_results, force_single_step, response_format, safety_mode, request_options)\u001b[39m\n\u001b[32m    990\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m typing.cast(\n\u001b[32m    991\u001b[39m         NonStreamedChatResponse,\n\u001b[32m    992\u001b[39m         construct_type(\n\u001b[32m   (...)\u001b[39m\u001b[32m    995\u001b[39m         ),\n\u001b[32m    996\u001b[39m     )\n\u001b[32m    997\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _response.status_code == \u001b[32m400\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m998\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequestError(\n\u001b[32m    999\u001b[39m         typing.cast(\n\u001b[32m   1000\u001b[39m             typing.Optional[typing.Any],\n\u001b[32m   1001\u001b[39m             construct_type(\n\u001b[32m   1002\u001b[39m                 type_=typing.Optional[typing.Any],  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m   1003\u001b[39m                 object_=_response.json(),\n\u001b[32m   1004\u001b[39m             ),\n\u001b[32m   1005\u001b[39m         )\n\u001b[32m   1006\u001b[39m     )\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _response.status_code == \u001b[32m401\u001b[39m:\n\u001b[32m   1008\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnauthorizedError(\n\u001b[32m   1009\u001b[39m         typing.cast(\n\u001b[32m   1010\u001b[39m             typing.Optional[typing.Any],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1015\u001b[39m         )\n\u001b[32m   1016\u001b[39m     )\n",
      "\u001b[31mBadRequestError\u001b[39m: status_code: 400, body: {'id': 'e87387ae-1d15-4515-8885-c9268ab8d03b', 'message': 'too many tokens: max tokens must be less than or equal to 4096, the maximum output for this model - received 5000.'}"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "\n",
    "co = cohere.Client(\"W0ZMiF8D4eU3eMGgZevXJMPwnJMzJVtd7JYwvo0V\")  # No ClientV2 needed for most use cases\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r\",  # or \"command-a-03-2025\" if you have access\n",
    "    message=\"Do you know haribabu kuthmpeta\",\n",
    "    max_tokens=4000,\n",
    "    temperature=0.65  # You can use just `message` for one-shot chat\n",
    ")\n",
    "\n",
    "print(\"Bot:\", response.text) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
